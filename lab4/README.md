## Valor-Go Lab4 说明文档
我们完成的是：llama.cpp部署Qwen3-1.7B
小组知乎文章：https://zhuanlan.zhihu.com/p/1923813736247964768
### 我们完成的任务列表
1. 拟定一份 LLM 部署相关的性能指标列表（不少于 5 个指标，如输出速度、首 Token 返回延迟 等），并说明所选指标的合理性。
2. 设计测试任务（可以直接使用llama.cpp 自带的测试工具等），并根据测试任务，从指标列表中选择至少两个指标进行后续测试。
3. 选取一款合适的 LLM，完成单机版部署并进行性能测试。
4. 基于已有部署参数进行分析、测试和优化。优化以 llama.cpp 的配置参数修改为主，不必修改底层系统环境，但需给出相应分析。
5. 选取对于所选性能指标以及 LLM 输出质量影响最大的优化操作，分析并说明原因。
6. 完成基于 RPC 的分布式部署。
7. 将撰写的相关报告发布到公开媒体，如 CSDN、知乎或是自己的博客、channel，并在报告中提供链接。
