# Ray分布式计算框架调查报告

**PB23111615 任壮壮 OSH-team2**

## 一、调查背景
随着人工智能技术的快速发展，传统的机器学习框架已无法满足下一代AI应用对动态交互和实时学习的需求。Ray框架作为一种新兴的分布式计算框架，旨在填补这一空白。本次调查旨在了解Ray框架的设计理念、技术优势以及潜在的应用场景，并结合自身实际，决定该选题是否适合。

## 二、调查方法
文献研究：通过阅读相关技术论文和社区文章，了解Ray框架的核心技术细节。

案例分析：分析Ray在实际项目中的应用案例，评估其性能和适用性。

## 三、调查结果

### 1. Ray的背景

#### 是什么

Ray 是一个高效的分布式计算框架，专为大规模并行任务设计，广泛应用于机器学习、数据处理等领域。它通过简洁的编程模型和强大的计算模型，支持高效的资源调度和任务执行。

#### 为什么

Ray 是 UC Berkeley RISELab 出品的机器学习分布式框架。UC Berkeley 教授 Ion Stoica 写了一篇文章：The Future of Computing is Distributed。文章里详细说了 Ray 产生的原由。总结一下，就是当前主流的机器学习框架（如TensorFlow、PyTorch等）主要专注于监督学习和深度神经网络的训练，依赖于GPU和TPU等硬件加速。然而，下一代AI应用将更多地涉及强化学习（Reinforcement Learning），需要在动态环境中与环境交互并学习，Ray的出现旨在满足下一代AI应用的需求，支持动态环境中的连续交互和长期目标的实现。

***名词解释和具体阐述***

***监督学习：***

监督学习是当前最主流的机器学习范式之一。它的核心思想是通过大量标注好的数据（输入和对应的输出标签）来训练模型，使模型能够学习输入与输出之间的映射关系，广泛应用于图像识别、语音识别、自然语言处理等领域。

***依赖硬件加速：***

由于深度神经网络的复杂性（如多层网络结构、大量的参数），训练这些模型需要大量的计算资源。因此，主流框架（如TensorFlow、PyTorch）通常依赖于GPU（图形处理单元）和TPU（张量处理单元）等硬件加速器来提高训练速度。

***强化学习：***

强化学习是一种与环境进行动态交互的学习范式。在这种范式下，智能体（Agent）通过在环境中采取行动（Action）来获得奖励（Reward），并通过奖励信号来优化其行为策略，其目标是让智能体学会在一系列动作中最大化长期累积奖励，而不是仅仅对输入数据进行分类或回归，其特点是动态环境、长期目标、实施决策。

***监督学习和强化学习的比较***

监督学习很大程度上有局限性，由于其通常基于静态数据集进行训练，模型的性能依赖于数据的质量和多样性。一旦数据分布发生变化（如环境变化或新任务出现），模型可能需要重新训练。因此，模型通常不具备与环境动态交互的能力，其主要在训练阶段学习数据的模式，而在实际应用中只是被动地对输入数据进行预测，无法根据环境反馈进行实时调整。

强化学习适用于动态环境，关注的是长期目标，而不仅仅是短期奖励，根据当前环境状态实时做出决策，并根据环境反馈调整策略，即强化学习的三个特点。

***为什么现有的框架无法满足强化学习的需求？***

缺乏动态交互支持：现有的框架（如TensorFlow、PyTorch）主要设计用于处理静态数据集，缺乏对动态交互的支持。强化学习需要在训练过程中实时与环境交互，而这些框架无法高效地支持这种交互。


任务调度和资源管理：强化学习通常需要同时运行多个智能体或多个环境实例，以加速学习过程。现有的框架在任务调度和资源管理方面可能不够灵活，无法高效地支持大规模的并行计算。

实时性要求：强化学习需要实时决策和反馈，而现有的框架在延迟和响应速度上可能无法满足这些需求。

### 2. Ray的技术优势

#### Task和Actor

Task和Actor是Ray编程模型中的两个重要概念，Task指无状态计算，Actor指有状态计算。

***实例分析***

***Task***

    # 声明两个功能相同的函数，一个是Ray任务，另一个是普通的Python函数
    @ray.remote

    def append_one(container):
        container.append(1)
        return container

    def local_append_one(container):
        container.append(1)
        return container

    container = []

    object_ref = append_one.remote(container)

    result = ray.get(object_ref) # 此处可确保函数已经在远程执行完成
    
    print(result) # [1]
    print(container) # []; 远程函数未对container产生副作用

    local_append_one(container)
    print(container) # [1]; 本地函数对container产生了副作用

这样设计的优点是能在函数执行出错时自动重新执行函数（因为不依赖于其他任务，可以在任意时候独立地执行），以提高容错性；缺点是限制了函数对全局变量或内存引用的访问。

***Actor***

    @ray.remote
    class Counter(object):
        def __init__(self):
            self.value = 0

        def increment(self):
            self.value += 1
            return self.value

    counter = Counter.remote()

    refs = []

    for i in range(10):
        ref = counter.increment.remote()
        refs.append(ref)

    for i, ref in enumerate(refs):
        assert ray.get(ref) == i + 1

Task中使用f.remote顺序地提交若干个远程函数后，这些函数是并行执行的，但在同一个Actor下使用actor.method.remote顺序地提交若干个远程方法后，这些方法将串行地执行。但是，不同Actor之间的调用是可以并行的。

#### Ray的计算方法

Ray采用动态任务图计算模型，在这一模型中，当输入数据就绪时，系统将自动触发相应的远程函数和行动器方法的执行。

***名词解释和具体阐述***

***动态任务图计算模型***

***是什么***

动态任务图计算模型（Dynamic Task Graph Computation Model）是一种在运行时动态构建和执行任务依赖关系的计算模型。与传统的静态任务图不同，动态任务图允许在执行过程中根据输入数据和任务状态实时调整任务的依赖关系和执行顺序。

***核心特点***

**动态构建**：任务图的结构在运行时根据输入数据和任务需求动态生成，而不是在程序启动时预先定义。

**灵活性**：支持任务的动态添加、删除和修改，能够适应复杂的、不确定的计算需求。

**异步执行**：任务可以异步执行，通过任务句柄（如 future）传递依赖关系，从而实现
高效的并行计算。

**事件驱动**：任务的执行依赖于输入数据的可用性，当输入数据准备好时，任务自动触发执行。

***Ray中的体现***
Ray 框架通过动态任务图计算模型支持任务并行化和 Actor 编程模型。具体实现包括：

**任务模型（Tasks）**：任务表示一个远程函数，其结果以 future 的形式返回。future 可以作为其他任务的输入，从而构建复杂的任务依赖关系。

**Actor 模型**：允许创建远程对象（Actor），其方法可以异步调用，并维护内部状态。

**高效调度**：通过本地调度器和全局调度器的两层调度架构，动态任务图能够实现高效的负载均衡和资源管理。

***优点***

**高效资源利用**：动态任务图可以根据任务的依赖关系动态分配资源，减少等待时间和资源浪费。

**适应性强**：能够适应动态变化的输入数据和任务需求，适合复杂的、不确定的计算任务。

**易于调试**：由于任务图是动态构建的，开发者可以在运行时查看和修改任务依赖关系。

**这些优点都与强化学习的需要很契合！**

#### Ray的架构

Ray的架构由**应用层**和**系统层**组成，其中应用层实现了Ray的API，作为前端供用户使用，而系统层则作为后端来保障Ray的高可扩展性和容错性。

应用层中有三种类型的进程：

**驱动器进程 (Driver Process):** 执行用户程序的进程。

**工作器进程 (Worker Process):** 在同一个工作器中，任务是串行地执行的，工作器并不维护其任务与任务之间的局部状态，即在工作器中，一个远程函数执行完后，其局部作用域的所有变量将不再能被其他任务所访问。

**行动器进程 (Actor Process):** 与工作器相同的是，行动器也会串行地执行任务，不同的是行动器上执行的每个方法都依赖于其前面所执行的方法所导致的状态。

系统层由三个主要部件组成：**全局控制存储器 (Global Control Store)**、**分布式调度器 (Distributed Scheduler)**和**分布式对象存储器 (Distributed Object Store)**。这些部件在横向上是可扩展的，即可以增减这些部件的数量，同时还具有一定的容错性。

### 3. Ray的应用场景

**强化学习**：在动态环境中进行实时决策和学习，如机器人控制、智能交通等。

**在线学习**：支持大规模数据的实时处理和模型更新，适用于金融风险预测、广告推荐等领域。

**通用计算**：适用于需要大规模并行计算的任务，如图像处理、自然语言处理等。

### 4. Ray的潜在挑战

**学习曲线**：尽管Ray提供了灵活的编程模型，但对于初学者来说，仍需要一定时间来掌握其核心概念和开发技巧。

**生态系统**：与TensorFlow、PyTorch等成熟框架相比，Ray的生态系统还不够完善，缺乏丰富的工具和库支持。

**性能优化**：在大规模集群环境中，任务调度和资源管理的效率仍需进一步优化，以应对复杂的计算任务。

## 四、总结

Ray对于初学者来说不好掌握，需要耗费大量的时间精力，但如果学好了可以做的方向很多，可以选一些Ray下的小方向比如丰富Ray的某个工具、库，但这些方向也有很大挑战，也许可以参考PyTorch这些有而Ray没有的优势功能。

一些可能的方向：

**1. 分布式数据处理功能**

**数据分区原语**：Ray目前缺乏内置的数据分区原语，这使得它在分布式数据处理方面不如Spark等框架强大。

**查询优化和数据处理功能**：Spark提供了丰富的查询优化和数据处理功能（如Stage级别的代码生成、straggler mitigation等），而Ray在这些方面相对欠缺。

**2. GPU支持的完整性**

**GPU资源管理**：Ray目前仅支持GPU的调度和预留，实际的GPU计算依赖于外部库（如TensorFlow、PyTorch），而不是直接集成到Ray框架中。

**3. 生态系统和工具链**

**模型管理和服务**：Ray的生态系统中缺乏类似TensorFlow Serving或Clipper这样的模型管理和部署工具。

**数据处理生态**：与Spark相比，Ray的分布式数据处理生态（如Ray Datasets）相对较新，功能不够完善。

**4. 监控和调试工具**

**监控功能**：Ray的监控工具（如Ray Dashboard）在大规模集群环境中的功能可能不如Spark或其他成熟框架强大。

**调试支持**：Ray的调试工具在复杂场景下的支持不够完善，可能需要额外的工具或手动干预。

**5. 特定场景的优化**

**大规模图数据处理**：Ray在大规模图数据处理方面缺乏专门的优化，而其他框架（如Apache Spark GraphX）提供了更成熟的支持。

**实时数据流处理**：Ray在实时数据流处理方面的能力不如Apache Flink或Spark Streaming。

**6. 跨平台支持**

**Windows支持**：Ray在Windows平台上的支持仍处于Beta阶段，而其他框架（如Spark）在Windows上的支持更为成熟

## 五、参考网站

**github源**：https://github.com/ray-project/ray

**Ray中文问答社区**：https://ray.osanswer.net/

**Ray开发者论坛**：https://discuss.ray.io/

**知乎专栏**：https://zhuanlan.zhihu.com/p/460600694

## 六. 基于Ray框架的分布式计算大作业选题方向

## 1. 基于Ray的分布式任务调度模拟器
- **背景**：Ray框架的核心功能之一是动态任务图计算模型和高效的调度机制。可以设计一个简化版的分布式任务调度模拟器，模拟Ray框架的任务调度过程。
- **实现内容**：
  - 使用Python或其他编程语言实现一个任务调度系统，支持任务的提交、执行和结果返回。
  - 模拟动态任务图的构建和执行，支持任务之间的依赖关系。
  - 设计一个简单的调度算法，如轮询调度或基于优先级的调度。
  - 提供一个简单的用户界面或命令行工具，用于提交任务和查看任务执行状态。
- **难度**：中等  
- **收获**：理解分布式任务调度的基本原理，掌握任务依赖关系的处理和调度算法的设计。

## 2. 基于Ray的分布式计算框架的资源管理器
- **背景**：Ray框架通过全局控制存储器和分布式调度器管理资源。可以设计一个资源管理器，模拟Ray框架的资源分配和管理机制。
- **实现内容**：
  - 设计一个资源管理器，支持CPU、内存等资源的分配和回收。
  - 实现一个简单的资源分配算法，如固定分配或动态分配。
  - 提供一个接口，允许用户查询当前资源的使用情况。
  - 模拟多个任务对资源的竞争，并展示资源分配的结果。
- **难度**：中等  
- **收获**：理解资源管理的基本概念，掌握资源分配算法的设计和实现。

## 3. 基于Ray的分布式文件系统模拟
- **背景**：Ray框架的分布式对象存储器用于存储任务的中间结果和数据。可以设计一个简单的分布式文件系统，模拟Ray框架的对象存储机制。
- **实现内容**：
  - 使用Python或其他编程语言实现一个分布式文件系统，支持文件的创建、读取、写入和删除。
  - 设计一个简单的数据存储结构，如哈希表或分布式文件块。
  - 实现文件的分片存储和冗余机制，提高系统的容错性。
  - 提供一个简单的用户界面或命令行工具，用于操作文件系统。
- **难度**：中等  
- **收获**：理解分布式文件系统的基本原理，掌握数据存储和容错机制的设计。

## 4. 基于Ray的分布式计算框架的监控工具
- **背景**：Ray框架的监控工具（如Ray Dashboard）用于监控任务的执行状态和资源使用情况。可以设计一个简单的监控工具，模拟Ray框架的监控功能。
- **实现内容**：
  - 设计一个监控工具，支持任务的执行状态监控和资源使用情况的实时展示。
  - 使用Python或其他编程语言实现一个简单的监控系统，支持任务的提交、执行和监控。
  - 提供一个简单的用户界面，展示任务的执行进度、资源使用情况等信息。
  - 实现一个简单的日志记录功能，记录任务的执行过程和资源使用情况。
- **难度**：中等  
- **收获**：理解监控工具的基本功能，掌握任务状态和资源使用情况的监控方法。

## 5. 基于Ray的分布式计算框架的容错机制模拟
- **背景**：Ray框架通过任务的重新执行和冗余存储实现容错。可以设计一个容错机制模拟器，模拟Ray框架的容错过程。
- **实现内容**：
  - 设计一个容错机制模拟器，支持任务的重新执行和数据的冗余存储。
  - 实现一个简单的容错算法，如任务重试机制或数据备份机制。
  - 模拟任务执行失败的情况，并展示容错机制的处理过程。
  - 提供一个简单的用户界面或命令行工具，用于提交任务和查看容错机制的执行结果。
- **难度**：中等  
- **收获**：理解容错机制的基本概念，掌握任务重试和数据备份机制的设计。

## 6. 基于Ray的分布式计算框架的Actor模型模拟
- **背景**：Ray框架的Actor模型用于支持有状态的计算。可以设计一个Actor模型模拟器，模拟Ray框架的Actor机制。
- **实现内容**：
  - 设计一个Actor模型模拟器，支持Actor的创建、方法调用和状态维护。
  - 使用Python或其他编程语言实现一个简单的Actor模型，支持多个Actor之间的通信和状态共享。
  - 提供一个简单的用户界面或命令行工具，用于创建Actor和调用方法。
  - 模拟多个Actor之间的交互过程，并展示Actor的状态变化。
- **难度**：中等  
- **收获**：理解Actor模型的基本概念，掌握Actor的创建、方法调用和状态维护的方法。

## 7. 基于Ray的分布式计算框架的GPU资源管理模拟
- **背景**：Ray框架支持GPU资源的调度和预留。学生可以设计一个GPU资源管理模拟器，模拟Ray框架的GPU资源管理过程。
- **实现内容**：
  - 设计一个GPU资源管理模拟器，支持GPU资源的分配和回收。
  - 使用Python或其他编程语言实现一个简单的GPU资源管理系统，支持GPU资源的申请、分配和释放。
  - 提供一个简单的用户界面或命令行工具，用于查询GPU资源的使用情况。
  - 实现一个简单的GPU资源分配算法，如轮询分配或优先级分配。
- **难度**：中等  
- **收获**：理解GPU资源管理的基本概念，掌握GPU资源分配算法的设计和实现。