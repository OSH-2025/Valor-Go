// src/fuse/FuseAppConfig.rs
use std::string::String;
use std::vec::Vec;
/*
#[derive(Debug)]
pub struct KeyValue {
    pub key: String,
    pub value: String,
}*/
#[derive(Debug, Clone)]
pub struct KeyValue {
    pub key: String,
    pub value: String,
}
impl KeyValue {
    pub fn new(key: String, value: String) -> Self {
        KeyValue { key, value }
    }
}

pub trait ConfigBase {
    fn init(&mut self, file_path: &str, dump: bool, updates: Vec<KeyValue>) -> Result<(), String>;
}

pub struct FuseAppConfig {
    node_id: u64,
}

impl FuseAppConfig {
    pub fn new() -> Self {
        FuseAppConfig { node_id: 0 }
    }

    pub fn init(&mut self, file_path: &str, dump: bool, updates: Vec<KeyValue>) {
        let res = ApplicationBase::init_config(self, file_path, dump, updates);
        if let Err(e) = res {
            panic!("Init app config failed: {:?}. filePath: {}. dump: {}", e, file_path, dump);
        }
    }

    pub fn get_node_id(&self) -> u64 {
        self.node_id
    }
}

pub struct ApplicationBase;

impl ApplicationBase {
    pub fn init_config(
        config: &mut FuseAppConfig,
        file_path: &str,
        dump: bool,
        updates: Vec<KeyValue>,
    ) -> Result<(), String> {
        // TODO: 实际配置加载逻辑
        Ok(())
    }
}

// src/fuse/FuseApplication.rs
use crate::fuse_app_config::KeyValue;


use std::collections::HashMap;

// 模拟配置对象
pub trait ConfigBase {
    fn init(&mut self, file_path: &str, dump: bool, updates: Vec<KeyValue>);
}

// FuseAppConfig 结构体（已在 fuse_app_config.rs 中定义）
pub struct FuseAppConfig {
    pub node_id: u64,
}

impl FuseAppConfig {
    pub fn new() -> Self {
        FuseAppConfig { node_id: 0 }
    }

    pub fn init(&mut self, file_path: &str, dump: bool, updates: Vec<KeyValue>) {
        // 模拟配置初始化
        if dump {
            println!("Dumping default config...");
        }

        for kv in &updates {
            println!("Update: {} = {}", kv.key, kv.value);
        }

        self.node_id = 123;
    }
}

// AppInfo 结构体，用于返回应用信息
#[derive(Debug)]
pub struct AppInfo {
    pub node_id: u64,
    pub hostname: String,
}

// ApplicationBase trait：模拟 C++ 的抽象类接口
pub trait ApplicationBase {
    fn parse_flags(&mut self, argc: i32, argv: Vec<String>) -> Result<(), String>;
    fn init_application(&mut self) -> Result<(), String>;
    fn stop(&mut self);
    fn main_loop(&self) -> i32;
    fn get_config(&self) -> &dyn ConfigBase;
    fn info(&self) -> Option<&AppInfo>;
    fn config_pushable(&self) -> bool;
    fn on_config_updated(&self);
}

// FuseApplication 实现 ApplicationBase 接口
pub struct FuseApplication {
    impl_: FuseApplicationImpl,
}

struct FuseApplicationImpl {
    hf3fs_config: FuseAppConfig,
    app_info: AppInfo,
    config_flags: HashMap<String, String>,
    program_name: String,
    allow_other: bool,
    mountpoint: String,
    max_buf_size: usize,
    cluster_id: String,
}

impl FuseApplication {
    pub fn new() -> Self {
        Self {
            impl_: FuseApplicationImpl {
                hf3fs_config: FuseAppConfig::new(),
                app_info: AppInfo {
                    node_id: 0,
                    hostname: "localhost".to_string(),
                },
                config_flags: HashMap::new(),
                program_name: "rust_fuse".to_string(),
                allow_other: false,
                mountpoint: "/mnt/hf3fs".to_string(),
                max_buf_size: 1024 * 1024,
                cluster_id: "default".to_string(),
            },
        }
    }
}

impl ApplicationBase for FuseApplication {
    fn parse_flags(&mut self, argc: i32, argv: Vec<String>) -> Result<(), String> {
        // 简单模拟命令行参数解析
        for arg in &argv {
            if arg == "--allow-other" {
                self.impl_.allow_other = true;
            } else if arg.starts_with("--mountpoint=") {
                let parts: Vec<&str> = arg.split('=').collect();
                if parts.len() == 2 {
                    self.impl_.mountpoint = parts[1].to_string();
                }
            } else if arg.starts_with("--cluster-id=") {
                let parts: Vec<&str> = arg.split('=').collect();
                if parts.len() == 2 {
                    self.impl_.cluster_id = parts[1].to_string();
                }
            }
        }

        // 模拟加载配置标志
        self.impl_.config_flags.insert(
            "test_key".to_string(),
            "test_value".to_string(),
        );

        Ok(())
    }

    fn init_application(&mut self) -> Result<(), String> {
        // 模拟打印默认配置
        if self.config_pushable() {
            println!("Dumping default config...");
            println!("{}", self.impl_.hf3fs_config_to_string());
        }

        // 初始化组件
        println!("Init common components...");
        self.impl_.app_info.node_id = 123;

        // 模拟配置初始化
        self.impl_.hf3fs_config.init(&self.impl_.mountpoint, true, vec![]);

        // 模拟持久化配置
        self.on_config_updated();

        Ok(())
    }

    fn stop(&mut self) {
        // 停止 fuse 客户端
        println!("Stopping fuse clients...");
    }

    fn main_loop(&self) -> i32 {
        // 主循环逻辑
        println!("Running fuse main loop...");
        std::thread::sleep(std::time::Duration::from_secs(5));
        println!("Main loop exited.");
        0
    }

    fn get_config(&self) -> &dyn ConfigBase {
        &self.impl_.hf3fs_config
    }

    fn info(&self) -> Option<&AppInfo> {
        Some(&self.impl_.app_info)
    }

    fn config_pushable(&self) -> bool {
        // 模拟是否可以推送配置
        true
    }

    fn on_config_updated(&self) {
        // 配置更新回调
        println!("Persisting config...");
    }
}

impl FuseApplicationImpl {
    fn hf3fs_config_to_string(&self) -> String {
        format!(
            "Mountpoint: {}\nMaxBufSize: {}\nClusterID: {}",
            self.mountpoint, self.max_buf_size, self.cluster_id
        )
    }
}

// 给FuseAppConfig实现ConfigBase trait
impl ConfigBase for FuseAppConfig {
    fn init(&mut self, file_path: &str, dump: bool, updates: Vec<KeyValue>) {
        self.init(file_path, dump, updates)
    }
}

// src/fuse/FuseAppConfig.cc
#include "FuseAppConfig.h"

#include "common/app/ApplicationBase.h"

namespace hf3fs::fuse {
void FuseAppConfig::init(const String &filePath, bool dump, const std::vector<config::KeyValue> &updates) {
  auto res = ApplicationBase::initConfig(*this, filePath, dump, updates);
  XLOGF_IF(FATAL, !res, "Init app config failed: {}. filePath: {}. dump: {}", res.error(), filePath, dump);
}
}  // namespace hf3fs::fuse


// src/fuse/FuseAppConfig.h
#pragma once

#include "common/app/NodeId.h"
#include "common/net/ib/IBDevice.h"
#include "common/utils/ConfigBase.h"

namespace hf3fs::fuse {
struct FuseAppConfig : public ConfigBase<FuseAppConfig> {
 public:
  using Base = ConfigBase<FuseAppConfig>;
  using Base::init;

  void init(const String &filePath, bool dump, const std::vector<config::KeyValue> &updates);
  flat::NodeId getNodeId() const { return flat::NodeId(0); }
};
}  // namespace hf3fs::fuse




// src/fuse/FuseApplication.cc
#ifdef ENABLE_FUSE_APPLICATION

#include "FuseApplication.h"

#include "FuseMainLoop.h"
#include "FuseOps.h"
#include "common/app/Thread.h"
#include "common/app/Utils.h"

DECLARE_string(cfg);
DECLARE_bool(dump_default_cfg);
DECLARE_bool(use_local_cfg);

namespace hf3fs::fuse {

struct FuseApplication::Impl {
  Result<Void> parseFlags(int *argc, char ***argv);
  Result<Void> initApplication();
  Result<Void> initFuseClients();
  void stop();
  int mainLoop();

  Config hf3fsConfig;
  flat::AppInfo appInfo;
  std::unique_ptr<Launcher> launcher_ = std::make_unique<Launcher>();

  std::unique_ptr<ConfigCallbackGuard> onLogConfigUpdated_;
  std::unique_ptr<ConfigCallbackGuard> onMemConfigUpdated_;

  ConfigFlags configFlags_;
  String programName;
  bool allowOther = false;
  String configMountpoint;
  size_t configMaxBufSize = 0;
  String configClusterId;
};

FuseApplication::FuseApplication()
    : impl_(std::make_unique<Impl>()) {}

FuseApplication::~FuseApplication() = default;

Result<Void> FuseApplication::Impl::parseFlags(int *argc, char ***argv) {
  RETURN_ON_ERROR(launcher_->parseFlags(argc, argv));

  static constexpr std::string_view dynamicConfigPrefix = "--config.";
  RETURN_ON_ERROR(ApplicationBase::parseFlags(dynamicConfigPrefix, argc, argv, configFlags_));

  programName = (*argv)[0];
  return Void{};
}

Result<Void> FuseApplication::parseFlags(int *argc, char ***argv) { return impl_->parseFlags(argc, argv); }

Result<Void> FuseApplication::Impl::initApplication() {
  if (FLAGS_dump_default_cfg) {
    fmt::print("{}\n", hf3fsConfig.toString());
    exit(0);
  }

  auto firstInitRes = launcher_->init();
  XLOGF_IF(FATAL, !firstInitRes, "Failed to init launcher: {}", firstInitRes.error());

  app_detail::loadAppInfo([this] { return launcher_->loadAppInfo(); }, appInfo);
  app_detail::initConfig(hf3fsConfig, configFlags_, appInfo, [this] { return launcher_->loadConfigTemplate(); });
  XLOGF(INFO, "Server config inited");

  app_detail::initCommonComponents(hf3fsConfig.common(), kName, appInfo.nodeId);

  onLogConfigUpdated_ = app_detail::makeLogConfigUpdateCallback(hf3fsConfig.common().log(), kName);
  onMemConfigUpdated_ = app_detail::makeMemConfigUpdateCallback(hf3fsConfig.common().memory(), appInfo.hostname);

  XLOGF(INFO, "Full Config:\n{}", hf3fsConfig.toString());
  app_detail::persistConfig(hf3fsConfig);

  XLOGF(INFO, "Start to init fuse clients");
  auto initRes = initFuseClients();
  XLOGF_IF(FATAL, !initRes, "Init fuse clients failed: {}", initRes.error());
  XLOGF(INFO, "Init fuse clients finished");

  launcher_.reset();

  return Void{};
}

Result<Void> FuseApplication::Impl::initFuseClients() {
  const auto &launcherConfig = launcher_->launcherConfig();
  allowOther = launcherConfig.allow_other();
  configMountpoint = launcherConfig.mountpoint();
  configMaxBufSize = hf3fsConfig.io_bufs().max_buf_size();
  configClusterId = launcherConfig.cluster_id();

  auto &d = getFuseClientsInstance();
  RETURN_ON_ERROR(d.init(appInfo, launcherConfig.mountpoint(), launcherConfig.token_file(), hf3fsConfig));
  return Void{};
}

Result<Void> FuseApplication::initApplication() { return impl_->initApplication(); }

void FuseApplication::Impl::stop() {
  getFuseClientsInstance().stop();
  hf3fs::stopAndJoin(nullptr);
}

void FuseApplication::stop() { impl_->stop(); }

config::IConfig *FuseApplication::getConfig() { return &impl_->hf3fsConfig; }

const flat::AppInfo *FuseApplication::info() const { return &impl_->appInfo; }

bool FuseApplication::configPushable() const { return FLAGS_cfg.empty() && !FLAGS_use_local_cfg; }

void FuseApplication::onConfigUpdated() { app_detail::persistConfig(impl_->hf3fsConfig); }

int FuseApplication::Impl::mainLoop() {
  Thread::unblockInterruptSignals();

  return fuseMainLoop(programName, allowOther, configMountpoint, configMaxBufSize, configClusterId);
}

int FuseApplication::mainLoop() { return impl_->mainLoop(); }

}  // namespace hf3fs::fuse

#endif


//src/fuse/FuseApplication.h
#pragma once

#ifdef ENABLE_FUSE_APPLICATION

#include "FuseAppConfig.h"
#include "FuseConfig.h"
#include "FuseConfigFetcher.h"
#include "FuseLauncherConfig.h"
#include "common/app/ApplicationBase.h"
#include "core/app/ServerLauncher.h"

namespace hf3fs::fuse {
class FuseApplication : public ApplicationBase {
 public:
  static constexpr auto kName = "Fuse";
  static constexpr auto kNodeType = flat::NodeType::FUSE;

  using AppConfig = FuseAppConfig;
  using LauncherConfig = FuseLauncherConfig;
  using RemoteConfigFetcher = FuseConfigFetcher;
  using Launcher = core::ServerLauncher<FuseApplication>;

  using Config = FuseConfig;

  FuseApplication();
  ~FuseApplication();

 private:
  Result<Void> parseFlags(int *argc, char ***argv) final;

  Result<Void> initApplication() final;

  void stop() final;

  int mainLoop() final;

  config::IConfig *getConfig() final;

  const flat::AppInfo *info() const final;

  bool configPushable() const final;

  void onConfigUpdated() final;

 private:
  Result<Void> initServer();

  Result<Void> startServer();

  struct Impl;
  std::unique_ptr<Impl> impl_;
};
}  // namespace hf3fs::fuse

#endif

//src/fuse/FuseClients.cc
#include "FuseClients.h"

#include <folly/Random.h>
#include <folly/ScopeGuard.h>
#include <folly/executors/IOThreadPoolExecutor.h>
#include <folly/experimental/coro/BlockingWait.h>
#include <folly/functional/Partial.h>
#include <folly/logging/xlog.h>
#include <fuse3/fuse_lowlevel.h>
#include <memory>
#include <thread>
#include <utility>

#include "common/app/ApplicationBase.h"
#include "common/monitor/Recorder.h"
#include "common/utils/BackgroundRunner.h"
#include "common/utils/Coroutine.h"
#include "common/utils/Duration.h"
#include "common/utils/FileUtils.h"
#include "common/utils/SysResource.h"
#include "fbs/meta/Common.h"
#include "fbs/mgmtd/Rpc.h"
#include "stubs/MetaService/MetaServiceStub.h"
#include "stubs/common/RealStubFactory.h"
#include "stubs/mgmtd/MgmtdServiceStub.h"

namespace hf3fs::fuse {
namespace {
monitor::ValueRecorder dirtyInodesCnt("fuse.dirty_inodes");

Result<Void> establishClientSession(client::IMgmtdClientForClient &mgmtdClient) {
  return folly::coro::blockingWait([&]() -> CoTryTask<void> {
    auto retryInterval = std::chrono::milliseconds(10);
    constexpr auto maxRetryInterval = std::chrono::milliseconds(1000);
    Result<Void> res = Void{};
    for (int i = 0; i < 40; ++i) {
      res = co_await mgmtdClient.extendClientSession();
      if (res) break;
      XLOGF(CRITICAL, "Try to establish client session failed: {}\nretryCount: {}", res.error(), i);
      co_await folly::coro::sleep(retryInterval);
      retryInterval = std::min(2 * retryInterval, maxRetryInterval);
    }
    co_return res;
  }());
}
}  // namespace

FuseClients::~FuseClients() { stop(); }

Result<Void> FuseClients::init(const flat::AppInfo &appInfo,
                               const String &mountPoint,
                               const String &tokenFile,
                               FuseConfig &fuseConfig) {
  config = &fuseConfig;

  fuseMount = appInfo.clusterId;
  XLOGF_IF(FATAL,
           fuseMount.size() >= 32,
           "FUSE only support mount name shorter than 32 characters, but {} got.",
           fuseMount);

  fuseMountpoint = Path(mountPoint).lexically_normal();

  if (fuseConfig.remount_prefix()) {
    fuseRemountPref = Path(*fuseConfig.remount_prefix()).lexically_normal();
  }

  if (const char *env_p = std::getenv("HF3FS_FUSE_TOKEN")) {
    XLOGF(INFO, "Use token from env var");
    fuseToken = std::string(env_p);
  } else {
    XLOGF(INFO, "Use token from config");
    auto tokenRes = loadFile(tokenFile);
    RETURN_ON_ERROR(tokenRes);
    fuseToken = folly::trimWhitespace(*tokenRes);
  }
  enableWritebackCache = fuseConfig.enable_writeback_cache();
  memsetBeforeRead = fuseConfig.memset_before_read();
  maxIdleThreads = fuseConfig.max_idle_threads();
  int logicalCores = std::thread::hardware_concurrency();
  if (logicalCores != 0) {
    maxThreads = std::min(fuseConfig.max_threads(), (logicalCores + 1) / 2);
  } else {
    maxThreads = fuseConfig.max_threads();
  }
  bufPool = net::RDMABufPool::create(fuseConfig.io_bufs().max_buf_size(), fuseConfig.rdma_buf_pool_size());

  iovs.init(fuseRemountPref.value_or(fuseMountpoint), fuseConfig.iov_limit());
  iors.init(fuseConfig.iov_limit());
  userConfig.init(fuseConfig);

  if (!client) {
    client = std::make_unique<net::Client>(fuseConfig.client());
    RETURN_ON_ERROR(client->start());
  }
  auto ctxCreator = [this](net::Address addr) { return client->serdeCtx(addr); };
  if (!mgmtdClient) {
    mgmtdClient = std::make_shared<client::MgmtdClientForClient>(
        appInfo.clusterId,
        std::make_unique<stubs::RealStubFactory<mgmtd::MgmtdServiceStub>>(ctxCreator),
        fuseConfig.mgmtd());
  }

  auto physicalHostnameRes = SysResource::hostname(/*physicalMachineName=*/true);
  RETURN_ON_ERROR(physicalHostnameRes);

  auto containerHostnameRes = SysResource::hostname(/*physicalMachineName=*/false);
  RETURN_ON_ERROR(containerHostnameRes);

  auto clientId = ClientId::random(*physicalHostnameRes);

  mgmtdClient->setClientSessionPayload({clientId.uuid.toHexString(),
                                        flat::NodeType::FUSE,
                                        flat::ClientSessionData::create(
                                            /*universalId=*/*physicalHostnameRes,
                                            /*description=*/fmt::format("fuse: {}", *containerHostnameRes),
                                            appInfo.serviceGroups,
                                            appInfo.releaseVersion),
                                        // TODO: use real user info
                                        flat::UserInfo{}});

  mgmtdClient->setConfigListener(ApplicationBase::updateConfig);

  folly::coro::blockingWait(mgmtdClient->start(&client->tpg().bgThreadPool().randomPick()));
  folly::coro::blockingWait(mgmtdClient->refreshRoutingInfo(/*force=*/false));
  RETURN_ON_ERROR(establishClientSession(*mgmtdClient));

  storageClient = storage::client::StorageClient::create(clientId, fuseConfig.storage(), *mgmtdClient);

  metaClient =
      std::make_shared<meta::client::MetaClient>(clientId,
                                                 fuseConfig.meta(),
                                                 std::make_unique<meta::client::MetaClient::StubFactory>(ctxCreator),
                                                 mgmtdClient,
                                                 storageClient,
                                                 true /* dynStripe */);
  metaClient->start(client->tpg().bgThreadPool());

  iojqs.reserve(3);
  iojqs.emplace_back(new BoundedQueue<IoRingJob>(fuseConfig.io_jobq_sizes().hi()));
  iojqs.emplace_back(new BoundedQueue<IoRingJob>(fuseConfig.io_jobq_size()));
  iojqs.emplace_back(new BoundedQueue<IoRingJob>(fuseConfig.io_jobq_sizes().lo()));

  jitter = fuseConfig.submit_wait_jitter();

  auto &tp = client->tpg().bgThreadPool();
  auto coros = fuseConfig.batch_io_coros();
  for (int i = 0; i < coros; ++i) {
    auto exec = &tp.get(i % tp.size());
    co_withCancellation(cancelIos.getToken(), ioRingWorker(i, coros)).scheduleOn(exec).start();
  }

  ioWatches.reserve(3);
  for (int i = 0; i < 3; ++i) {
    ioWatches.emplace_back(folly::partial(&FuseClients::watch, this, i));
  }

  periodicSyncWorker = std::make_unique<CoroutinesPool<InodeId>>(config->periodic_sync().worker());
  periodicSyncWorker->start(folly::partial(&FuseClients::periodicSync, this), tp);

  periodicSyncRunner = std::make_unique<BackgroundRunner>(&tp.pickNextFree());
  periodicSyncRunner->start("PeriodSync", folly::partial(&FuseClients::periodicSyncScan, this), [&]() {
    return config->periodic_sync().interval() * folly::Random::randDouble(0.7, 1.3);
  });

  onFuseConfigUpdated = fuseConfig.addCallbackGuard([&fuseConfig = fuseConfig, this] {
    memsetBeforeRead = fuseConfig.memset_before_read();
    jitter = std::chrono::duration_cast<std::chrono::nanoseconds>(fuseConfig.submit_wait_jitter());
  });

  notifyInvalExec =
      std::make_unique<folly::IOThreadPoolExecutor>(fuseConfig.notify_inval_threads(),
                                                    std::make_shared<folly::NamedThreadFactory>("NotifyInvalThread"));

  return Void{};
}

void FuseClients::stop() {
  if (notifyInvalExec) {
    notifyInvalExec->stop();
    notifyInvalExec.reset();
  }
  if (onFuseConfigUpdated) {
    onFuseConfigUpdated.reset();
  }

  cancelIos.requestCancellation();

  for (auto &t : ioWatches) {
    t.request_stop();
  }
  if (periodicSyncRunner) {
    folly::coro::blockingWait(periodicSyncRunner->stopAll());
    periodicSyncRunner.reset();
  }
  if (periodicSyncWorker) {
    periodicSyncWorker->stopAndJoin();
    periodicSyncWorker.reset();
  }
  if (metaClient) {
    metaClient->stop();
    metaClient.reset();
  }
  if (storageClient) {
    storageClient->stop();
    storageClient.reset();
  }
  if (mgmtdClient) {
    folly::coro::blockingWait(mgmtdClient->stop());
    mgmtdClient.reset();
  }
  if (client) {
    client->stopAndJoin();
    client.reset();
  }
}

CoTask<void> FuseClients::ioRingWorker(int i, int ths) {
  // a worker thread has its own priority, but it can also execute jobs from queues with a higher priority
  // checkHigher is used to make sure the job queue with the thread's own priority doesn't starve
  bool checkHigher = true;

  while (true) {
    auto res = co_await folly::coro::co_awaitTry([this, &checkHigher, i, ths]() -> CoTask<void> {
      IoRingJob job;
      auto hiThs = config->io_worker_coros().hi(), loThs = config->io_worker_coros().lo();
      auto prio = i < hiThs ? 0 : i < (ths - loThs) ? 1 : 2;
      if (!config->enable_priority()) {
        job = co_await iojqs[prio]->co_dequeue();
      } else {
        bool gotJob = false;

        // if checkHigher, dequeue from a higher job queue if it is full
        while (!gotJob) {
          if (checkHigher) {
            for (int nprio = 0; nprio < prio; ++nprio) {
              if (iojqs[nprio]->full()) {
                auto dres = iojqs[nprio]->try_dequeue();
                if (dres) {
                  // got a job from higher priority queue, next time pick a same priority job unless the queue is empty
                  checkHigher = false;
                  gotJob = true;
                  job = std::move(*dres);
                  break;
                }
              }
            }

            if (gotJob) {
              break;
            }
          }

          // if checkHigher, check from higher prio to lower; otherwise, reverse the checking direction
          for (int nprio = checkHigher ? 0 : prio; checkHigher ? nprio <= prio : nprio >= 0;
               nprio += checkHigher ? 1 : -1) {
            auto [sres, dres] =
                co_await folly::coro::collectAnyNoDiscard(folly::coro::sleep(config->io_job_deq_timeout()),
                                                          iojqs[nprio]->co_dequeue());
            if (dres.hasValue()) {
              // if the job is the thread's own priority, next time it can check from higher priority queues
              if (!checkHigher && nprio == prio) {
                checkHigher = true;
              }
              gotJob = true;
              job = std::move(*dres);
              break;
            } else if (sres.hasValue()) {
              continue;
            } else {
              dres.throwUnlessValue();
            }
          }
        }
      }

      while (true) {
        auto lookupFiles =
            [this](std::vector<std::shared_ptr<RcInode>> &ins, const IoArgs *args, const IoSqe *sqes, int sqec) {
              auto lastIid = 0ull;

              std::lock_guard lock(inodesMutex);
              for (int i = 0; i < sqec; ++i) {
                auto idn = args[sqes[i].index].fileIid;
                if (i && idn == lastIid) {
                  ins.emplace_back(ins.back());
                  continue;
                }

                lastIid = idn;
                auto iid = meta::InodeId(idn);
                auto it = inodes.find(iid);
                ins.push_back(it == inodes.end() ? (std::shared_ptr<RcInode>()) : it->second);
              }
            };
        auto lookupBufs =
            [this](std::vector<Result<lib::ShmBufForIO>> &bufs, const IoArgs *args, const IoSqe *sqe, int sqec) {
              auto lastId = Uuid::zero();
              std::shared_ptr<lib::ShmBuf> lastShm;

              std::lock_guard lock(iovs.shmLock);
              for (int i = 0; i < sqec; ++i) {
                auto &arg = args[sqe[i].index];
                Uuid id;
                memcpy(id.data, arg.bufId, sizeof(id.data));

                std::shared_ptr<lib::ShmBuf> shm;
                if (i && id == lastId) {
                  shm = lastShm;
                } else {
                  auto it = iovs.shmsById.find(id);
                  if (it == iovs.shmsById.end()) {
                    bufs.emplace_back(makeError(StatusCode::kInvalidArg, "buf id not found"));
                    continue;
                  }

                  auto iovd = it->second;
                  shm = iovs.iovs->table[iovd].load();
                  if (!shm) {
                    bufs.emplace_back(makeError(StatusCode::kInvalidArg, "buf id not found"));
                    continue;
                  } else if (shm->size < arg.bufOff + arg.ioLen) {
                    bufs.emplace_back(makeError(StatusCode::kInvalidArg, "invalid buf off and/or io len"));
                    continue;
                  }

                  lastId = id;
                  lastShm = shm;
                }

                bufs.emplace_back(lib::ShmBufForIO(std::move(shm), arg.bufOff));
              }
            };

        co_await job.ior->process(job.sqeProcTail,
                                  job.toProc,
                                  *storageClient,
                                  config->storage_io(),
                                  userConfig,
                                  std::move(lookupFiles),
                                  std::move(lookupBufs));

        if (iojqs[0]->full() || job.ior->priority != prio) {
          sem_post(iors.sems[job.ior->priority].get());  // wake the watchers
        } else {
          auto jobs = job.ior->jobsToProc(1);
          if (!jobs.empty()) {
            job = jobs.front();
            if (!iojqs[0]->try_enqueue(job)) {
              continue;
            }
          }
        }

        break;
      }
    }());
    if (UNLIKELY(res.hasException())) {
      XLOGF(INFO, "io worker #{} cancelled", i);
      if (res.hasException<OperationCancelled>()) {
        break;
      } else {
        XLOGF(FATAL, "got exception in io worker #{}", i);
      }
    }
  }
}

void FuseClients::watch(int prio, std::stop_token stop) {
  while (!stop.stop_requested()) {
    struct timespec ts;
    if (clock_gettime(CLOCK_REALTIME, &ts) < 0) {
      continue;
    }

    auto nsec = ts.tv_nsec + jitter.load().count();
    ts.tv_nsec = nsec % 1000000000;
    ts.tv_sec += nsec / 1000000000;
    if (sem_timedwait(iors.sems[prio].get(), &ts) < 0 && errno == ETIMEDOUT) {
      continue;
    }

    auto gotJobs = false;
    do {
      gotJobs = false;

      auto n = iors.ioRings->slots.nextAvail.load();
      for (int i = 0; i < n; ++i) {
        auto ior = iors.ioRings->table[i].load();

        if (ior && ior->priority == prio) {
          auto jobs = ior->jobsToProc(config->max_jobs_per_ioring());
          for (auto &&job : jobs) {
            gotJobs = true;
            iojqs[prio]->enqueue(std::move(job));
          }
        }
      }
    } while (gotJobs);  // loop till we found no more jobs and then block in the next iter
  }
}

CoTask<void> FuseClients::periodicSyncScan() {
  if (!config->periodic_sync().enable() || config->readonly()) {
    co_return;
  }

  XLOGF(INFO, "periodicSyncScan run");
  std::set<InodeId> dirty;
  {
    auto guard = dirtyInodes.lock();
    auto limit = config->periodic_sync().limit();
    dirtyInodesCnt.set(guard->size());
    if (guard->size() <= limit) {
      dirty = std::exchange(*guard, {});
    } else {
      XLOGF(WARN, "dirty inodes {} > limit {}", guard->size(), limit);
      auto iter = guard->find(lastSynced);
      while (dirty.size() < limit) {
        if (iter == guard->end()) {
          iter = guard->begin();
          XLOGF_IF(FATAL, iter == guard->end(), "iter == guard->end() shouldn't happen");
        } else {
          auto inode = *iter;
          lastSynced = inode;
          iter = guard->erase(iter);
          dirty.insert(inode);
        }
      }
    }
  }

  for (auto inode : dirty) {
    co_await periodicSyncWorker->enqueue(inode);
  }

  co_return;
}

}  // namespace hf3fs::fuse

//src/fuse/FuseClients.h
#pragma once

#include <algorithm>
#include <atomic>
#include <cstddef>
#include <cstdint>
#include <folly/MPMCQueue.h>
#include <folly/Math.h>
#include <folly/Synchronized.h>
#include <folly/Utility.h>
#include <folly/executors/IOThreadPoolExecutor.h>
#include <folly/experimental/coro/Mutex.h>
#include <folly/fibers/Semaphore.h>
#include <folly/logging/xlog.h>
#include <memory>
#include <mutex>
#include <optional>
#include <string>
#include <sys/types.h>
#include <thread>
#include <utility>

#include "common/utils/BackgroundRunner.h"
#include "common/utils/CoroutinesPool.h"
#include "common/utils/Result.h"
#include "common/utils/Semaphore.h"
#include "common/utils/UtcTime.h"
#include "fbs/core/user/User.h"
#include "fbs/meta/Common.h"
#define FUSE_USE_VERSION 312
#define OP_LOG_LEVEL DBG

#include <folly/concurrency/AtomicSharedPtr.h>
#include <fuse3/fuse_lowlevel.h>

#include "FuseConfig.h"
#include "IoRing.h"
#include "IovTable.h"
#include "PioV.h"
#include "UserConfig.h"
#include "client/meta/MetaClient.h"
#include "client/mgmtd/MgmtdClientForClient.h"
#include "client/storage/StorageClient.h"
#include "fbs/meta/Schema.h"

namespace hf3fs::fuse {
using flat::Gid;
using flat::Uid;
using flat::UserInfo;
using lib::agent::PioV;
using meta::Acl;
using meta::Directory;
using meta::DirEntry;
using meta::Inode;
using meta::InodeData;
using meta::InodeId;
using meta::Permission;
using storage::client::IOBuffer;

struct InodeWriteBuf {
  std::vector<uint8_t> buf;
  std::unique_ptr<storage::client::IOBuffer> memh;
  off_t off{0};
  size_t len{0};
};

struct RcInode {
  struct DynamicAttr {
    uint64_t written = 0;
    uint64_t synced = 0;   // period sync
    uint64_t fsynced = 0;  // fsync, close, truncate, etc...
    flat::Uid writer = flat::Uid(0);

    uint32_t dynStripe = 1;  // dynamic stripe

    uint64_t truncateVer = 0;                         // largest known truncate version.
    std::optional<meta::VersionedLength> hintLength;  // local hint length
    std::optional<UtcTime> atime;                     // local read time, but only update for write open
    std::optional<UtcTime> mtime;                     // local write time

    void update(const Inode &inode, uint64_t syncver = 0, bool fsync = false) {
      if (!inode.isFile()) {
        return;
      }

      synced = std::max(synced, syncver);
      if (written == synced) {
        // clear local hint, since not write happens after sync
        hintLength = meta::VersionedLength{0, 0};
      }
      if (fsync) {
        fsynced = std::max(fsynced, syncver);
      }
      truncateVer = std::max(truncateVer, inode.asFile().truncateVer);
      dynStripe = inode.asFile().dynStripe;
    }
  };

  Inode inode;
  int refcount;
  std::atomic<int> opened;

  std::mutex wbMtx;
  std::shared_ptr<InodeWriteBuf> writeBuf;

  folly::Synchronized<DynamicAttr> dynamicAttr;
  folly::coro::Mutex extendStripeLock;

  RcInode(Inode inode, int refcount = 1)
      : inode(inode),
        refcount(refcount),
        extendStripeLock() {
    if (inode.isFile()) {
      auto guard = dynamicAttr.wlock();
      guard->truncateVer = inode.asFile().truncateVer;
      guard->hintLength = meta::VersionedLength{0, guard->truncateVer};
      guard->dynStripe = inode.asFile().dynStripe;
    }
  }

  uint64_t getTruncateVer() const { return dynamicAttr.rlock()->truncateVer; }

  void update(const Inode &inode, uint64_t syncver = 0, bool fsync = false) {
    if (!inode.isFile()) {
      return;
    } else {
      auto guard = dynamicAttr.wlock();
      return guard->update(inode, syncver, fsync);
    }
  }

  // clear hint length, force calculate length on next sync
  void clearHintLength() {
    auto guard = dynamicAttr.wlock();
    guard->hintLength = std::nullopt;
  }

  CoTryTask<uint64_t> beginWrite(flat::UserInfo userInfo,
                                 meta::client::MetaClient &meta,
                                 uint64_t offset,
                                 uint64_t length);

  void finishWrite(flat::UserInfo userInfo, uint64_t truncateVer, uint64_t offset, ssize_t ret);
};

struct FileHandle {
  std::shared_ptr<RcInode> rcinode;
  bool oDirect;
  Uuid sessionId;

  /* FileHandle(std::shared_ptr<RcInode> rcinode, bool oDirect, Uuid sessionId) */
  /*       : rcinode(rcinode), */
  /*         sessionId(sessionId) {} */
};

struct DirHandle {
  size_t dirId;
  pid_t pid;
  bool iovDir;
};

struct DirEntryVector {
  std::shared_ptr<std::vector<DirEntry>> dirEntries;

  DirEntryVector(std::shared_ptr<std::vector<DirEntry>> &&dirEntries)
      : dirEntries(std::move(dirEntries)) {}
};

struct DirEntryInodeVector {
  std::shared_ptr<std::vector<DirEntry>> dirEntries;
  std::shared_ptr<std::vector<std::optional<Inode>>> inodes;

  DirEntryInodeVector(std::shared_ptr<std::vector<DirEntry>> dirEntries,
                      std::shared_ptr<std::vector<std::optional<Inode>>> inodes)
      : dirEntries(std::move(dirEntries)),
        inodes(std::move(inodes)) {}
};

struct FuseClients {
  FuseClients() = default;
  ~FuseClients();

  Result<Void> init(const flat::AppInfo &appInfo,
                    const String &mountPoint,
                    const String &tokenFile,
                    FuseConfig &fuseConfig);
  void stop();

  CoTask<void> ioRingWorker(int i, int ths);
  void watch(int prio, std::stop_token stop);

  CoTask<void> periodicSyncScan();
  CoTask<void> periodicSync(InodeId inodeId);

  std::unique_ptr<net::Client> client;
  std::shared_ptr<client::MgmtdClientForClient> mgmtdClient;
  std::shared_ptr<storage::client::StorageClient> storageClient;
  std::shared_ptr<meta::client::MetaClient> metaClient;

  std::string fuseToken;
  std::string fuseMount;
  Path fuseMountpoint;
  std::optional<Path> fuseRemountPref;
  std::atomic<bool> memsetBeforeRead = false;
  int maxIdleThreads = 0;
  int maxThreads = 0;
  bool enableWritebackCache = false;

  std::unique_ptr<ConfigCallbackGuard> onFuseConfigUpdated;

  std::unordered_map<InodeId, std::shared_ptr<RcInode>> inodes = {
      {InodeId::root(), std::make_shared<RcInode>(Inode{}, 2)}};
  std::mutex inodesMutex;

  std::unordered_map<uint64_t, DirEntryInodeVector> readdirplusResults;
  std::mutex readdirplusResultsMutex;

  std::atomic_uint64_t dirHandle{0};

  std::shared_ptr<net::RDMABufPool> bufPool;
  int maxBufsize = 0;

  fuse_session *se = nullptr;

  std::atomic<std::chrono::nanoseconds> jitter;

  IovTable iovs;
  IoRingTable iors;
  std::vector<std::unique_ptr<BoundedQueue<IoRingJob>>> iojqs;  // job queues
  std::vector<std::jthread> ioWatches;
  folly::CancellationSource cancelIos;

  UserConfig userConfig;

  folly::Synchronized<std::set<InodeId>, std::mutex> dirtyInodes;
  std::atomic<InodeId> lastSynced;
  std::unique_ptr<BackgroundRunner> periodicSyncRunner;
  std::unique_ptr<CoroutinesPool<InodeId>> periodicSyncWorker;

  std::unique_ptr<folly::IOThreadPoolExecutor> notifyInvalExec;
  const FuseConfig *config;
};
}  // namespace hf3fs::fuse

